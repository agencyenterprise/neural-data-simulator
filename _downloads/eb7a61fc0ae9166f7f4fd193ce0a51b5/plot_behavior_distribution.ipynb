{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Visualize distribution of velocities\n\n.. currentmodule:: nds\n\nThe goal of this example is to show the distribution of velocities used to train the\nmodel and compare it with the distribution of the velocities while running the center\nout reach task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set data source\nRetrieve the data from AWS S3\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from urllib.parse import urljoin\n\nimport pooch\n\nDOWNLOAD_BASE_URL = \"https://neural-data-simulator.s3.amazonaws.com/sample_data/v1/\"\n\nMONKEY_DATA_PATH = pooch.retrieve(\n    url=urljoin(DOWNLOAD_BASE_URL, \"monkey_velocities.npz\"),\n    known_hash=\"md5:b1ef650106210d65da2a3075e7767a21\",\n)\nHUMAN_DATA_PATH = pooch.retrieve(\n    url=urljoin(DOWNLOAD_BASE_URL, \"human_velocities.npz\"),\n    known_hash=\"md5:b2391f7759845f5256f651dc4e16fb6e\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load data\nLoad the data to be plotted.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import figure\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nmonkey_file = np.load(MONKEY_DATA_PATH)\nhuman_file = np.load(HUMAN_DATA_PATH)\n\nmonkey_data = monkey_file[\"arr_0\"]\nhuman_data = human_file[\"data\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scale monkey data\nMonkey data has to be scaled in the same way it was done when training the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n\nVELOCITY_LIMIT = 20\n\nscaler = StandardScaler()\nscaler.fit(monkey_data)\n\nmonkey_data = scaler.transform(monkey_data)\nmonkey_data = np.clip(monkey_data, -VELOCITY_LIMIT, VELOCITY_LIMIT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({\"font.size\": 14})\n\nfigure(figsize=(20, 5), dpi=180)\nplt.hist(human_data[:, 0], color=\"black\", bins=20, label=\"velocity x\", alpha=0.5)\nplt.hist(human_data[:, 1], color=\"red\", bins=20, label=\"velocity y\", alpha=0.5)\n\nplt.legend()\nplt.title(\"Human Velocities\")\nplt.show()\n\nfigure(figsize=(20, 5), dpi=180)\nplt.hist(monkey_data[:, 0], color=\"black\", bins=20, label=\"velocity x\", alpha=0.5)\nplt.hist(monkey_data[:, 1], color=\"red\", bins=20, label=\"velocity y\", alpha=0.5)\n\nplt.legend()\nplt.title(\"Monkey Velocities\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}